<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Shlok Gilda</title>
    <link>https://shlokgilda.github.io/project/</link>
      <atom:link href="https://shlokgilda.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 Shlok Gilda</copyright><lastBuildDate>Tue, 27 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://shlokgilda.github.io/media/icon_hu78d405b8dcc1dde0d74e011fa0cd641f_27924_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://shlokgilda.github.io/project/</link>
    </image>
    
    <item>
      <title>Analysis of Gender Bias and Discrimination in News Media</title>
      <link>https://shlokgilda.github.io/project/gender-bias/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://shlokgilda.github.io/project/gender-bias/</guid>
      <description>&lt;p&gt;We aim to analyze how the sentiment and toxicity of news articles vary based on the gender of authors, quoted sources,
etc. We hypothesize that if there is a statistically significant correlation between negative sentiment and/or high
toxicity and gender (of the authors/sources), then there is gender bias present in an article.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Different Types of Subtle Toxicity in Unhealthy Online Conversations</title>
      <link>https://shlokgilda.github.io/project/unhealthy-conversations/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://shlokgilda.github.io/project/unhealthy-conversations/</guid>
      <description>&lt;p&gt;We investigated the use of machine learning models for the classification of unhealthy online conversations
containing one or more forms of subtler abuse, such as hostility, sarcasm, and generalization. We leveraged a public
dataset of 44K online comments containing healthy and unhealthy comments labeled with seven forms of subtle toxicity.
We were able to distinguish between these comments with a top micro F1-score, macro F1-score, and ROC-AUC of 88.76%,
67.98%, and 0.71, respectively. Hostile comments were easier to detect than other types of unhealthy comments.
We also conducted a sentiment analysis which revealed that most types of unhealthy comments were associated with a
slight negative sentiment, with hostile comments being the most negative ones. We have a submitted a research paper on
this work at the 5th Workshop on Online Abuse and Harms (WOAH).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigation of Covid-19 related tweets for misinformation and engagement</title>
      <link>https://shlokgilda.github.io/project/covid-tweets/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://shlokgilda.github.io/project/covid-tweets/</guid>
      <description>&lt;p&gt;We examine nearly 505K COVID-19-related tweets from the initial months of the pandemic to understand misinformation as a
function of bot-behavior and engagement. Using a correlation-based feature selection method, we selected the 11 most
relevant feature subsets among over 170 features to distinguish misinformation from facts, and to predict highly
engaging misinformation tweets about COVID-19. We found that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;real users tweet both facts and misinformation, while bots tweet proportionally more misinformation.&lt;/li&gt;
&lt;li&gt;misinformation tweets were less engaging than facts.&lt;/li&gt;
&lt;li&gt;the textual content of a tweet was the most important to distinguish fact from misinformation.&lt;/li&gt;
&lt;li&gt;user account metadata and human-like activity were most important to predict high engagement in factual and
misinformation tweets.&lt;/li&gt;
&lt;li&gt;sentiment features were not relevant.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Investigation of Covid-19 related Android apps for malicious behavior and users’ engagement</title>
      <link>https://shlokgilda.github.io/project/covid-apps/</link>
      <pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://shlokgilda.github.io/project/covid-apps/</guid>
      <description>&lt;p&gt;We examine nearly 300K COVID-19-related Android applications to analyze the prevalence of malware among these
applications. We aim to find features (behavioral, sociolinguistic, etc.) which are more relevant to distinguish malware
infected applications from benign applications and features which are more relevant to distinguish highly engaging
applications from low engaging applications.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
